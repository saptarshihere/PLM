---
title: "Practical Machine Learning Assignment"
author: "Saptarshi Lahiri"
date: "11 September 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Summary Of Assignment
# This Report describes the way subjects perform weight lifting exercise. The data is collected from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. Two types of data sets have been provided for this assignment. The files have been locally downloaded.
#Training Data Set:
#https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

#Test Data Set:
#https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv


```{r }
#Set seed and define library
library(ElemStatLearn)
library(caret)
library(rpart)
library(randomForest)
library(RCurl)
set.seed(2014)
```


```{r }
#Data Preparation
setwd("E:/DataScience/Workspace/Groupware")
pml_trn_csv <- read.csv(file = "pml-training.csv", header=TRUE, sep=",", na.strings=c("NA",""))
pml_trn_csv <- pml_trn_csv[,-1]

#Have set working directory and loaded the pre downloaded file containing total 19622 observations of 159 variables (the first column representing the ID row is removed)
```

```{r }
inTrain = createDataPartition(pml_trn_csv$classe, p=0.60, list=FALSE)
training = pml_trn_csv[inTrain,]
validating = pml_trn_csv[-inTrain,]

# number of rows and columns of data in the training set

dim(training)

# number of rows and columns of data in the validating set

dim(validating)

```


```{r }
# Number of cols with less than 60% of data
sum((colSums(!is.na(training[,-ncol(training)])) < 0.6*nrow(training)))
# apply our definition of remove columns that most doesn't have data, before its apply to the model.

Keep <- c((colSums(!is.na(training[,-ncol(training)])) >= 0.6*nrow(training)))
training   <-  training[,Keep]
validating <- validating[,Keep]

# number of rows and columns of data in the final training set

dim(training)
dim(validating)
```

```{r }
#Random Forest model is chosen considering the non linearity of the data
model <- randomForest(classe~.,data=training)
print(model)
#Proceeding with the verification of variable importance measures as produced by random Forest
importance(model)
#Model result is verrified through confusion matrix
confusionMatrix(predict(model,newdata=validating[,-ncol(validating)]),validating$classe)

#Confirmed the accuracy of the validating data set

accuracy <-c(as.numeric(predict(model,newdata=validating[,-ncol(validating)])==validating$classe))

accuracy <-sum(accuracy)*100/nrow(validating)

#Model accuracy derived at 99.9%
```

```{r }

#Model testing starts here in order to
#1. To provide new values in the testing csv provided
#2. Perform similar cleaning operation
#3. Coerce columns of testing data set for the same class of previous data set
setwd("E:/DataScience/Workspace/Groupware")
pml_test_csv <- read.csv(file = "pml-testing.csv", header=TRUE, sep=",", na.strings=c("NA",""))
pml_test_csv <- pml_test_csv[,-1] # Remove the first column that represents a ID 
pml_test_csv <- pml_test_csv[ , Keep] # Keep the same columns of testing dataset
pml_test_csv <- pml_test_csv[,-ncol(pml_test_csv)] # Remove the problem ID
testing <- rbind(training[100, -59] , pml_test_csv)
row.names(testing) <- c(100, 1:20)
predictions <- predict(model,newdata=testing[-1,])
print(predictions)

```

```{r  }
endTime <- Sys.time()
endTime
```



Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
